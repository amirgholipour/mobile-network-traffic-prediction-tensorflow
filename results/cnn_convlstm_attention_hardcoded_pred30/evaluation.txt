Namespace(batch_size=1000, cnn_filters=[25, 50, 50], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50, 50], evaluation_steps=[10, 12], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[30, 30, 30], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_attention_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Namespace(batch_size=1000, cnn_filters=[25, 50, 50], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50, 50], evaluation_steps=[10, 12], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[30, 30, 30], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_attention_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Namespace(batch_size=1000, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50, 50], evaluation_steps=[10, 12], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Namespace(batch_size=1000, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50, 50], evaluation_steps=[10, 12], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_attention_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Namespace(batch_size=1000, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50, 50], evaluation_steps=[1, 10, 12, 30], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_attention_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Errors for all testing data:
Namespace(batch_size=1000, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50, 50], evaluation_steps=[1, 10, 12, 30], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_attention_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Errors for all testing data:
Namespace(batch_size=1000, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50, 50], evaluation_steps=[1, 10, 12, 30], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_attention_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Errors for all testing data:
mean 1 step nrmse loss: 0.3794138605647971
std: 0.03344084277710942
mean 10 step nrmse loss: 0.4459903399115589
std: 0.06500151635095087
mean 12 step nrmse loss: 0.46220981919247994
std: 0.07304819342133455
mean 30 step nrmse loss: 0.711116283767876
std: 0.16188734281977848


Trying 10 random samples:
mean 1 step nrmse loss: 0.3780698621947389
std: 0.022193657299706286
mean 10 step nrmse loss: 0.47099612860945533
std: 0.060992639762135765
mean 12 step nrmse loss: 0.493003770993961
std: 0.06970816229537184
mean 30 step nrmse loss: 0.7375050231246786
std: 0.15614254656195528
Namespace(batch_size=1000, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50], decoder_padding='same', dropout=0.0, encoder_filters=[50, 50], evaluation_steps=[1, 10, 12, 30], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[30, 30, 30], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/cnn_convlstm_attention_hardcoded_pred30/saved_models/train_model_9', model_name='cnn_convlstm_attention_hardcoded', num_epochs=100, num_layers=2, output_size=30, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

