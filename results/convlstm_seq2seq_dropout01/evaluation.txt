Namespace(batch_size=1, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50], evaluation_steps=[1, 10, 12], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.05, mlp_hidden_sizes=[50, 1], model_file='results/convlstm_seq2seq_dropout01/saved_models/train_model_16', model_name='convlstm_seq2seq', num_epochs=100, num_layers=2, output_size=12, pass_state=True, prediction_batch_size=1, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Errors for all testing data:
mean 1 step nrmse loss: 0.3832475887981848
std: 0.07046822806679812
mean 10 step nrmse loss: 0.43658482411308286
std: 0.0645699617312683
mean 12 step nrmse loss: 0.4497501550715522
std: 0.0655519881852598


Trying 10 random samples:
mean 1 step nrmse loss: 0.38884878735321793
std: 0.07595929508686144
mean 10 step nrmse loss: 0.4470086426458968
std: 0.056012124247075315
mean 12 step nrmse loss: 0.4598423572107935
std: 0.05142169744587646
Namespace(batch_size=1, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50], evaluation_steps=[1, 10, 12], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.1, mlp_hidden_sizes=[50, 1], model_file='results/convlstm_seq2seq_dropout01/saved_models/train_model_16', model_name='convlstm_seq2seq', num_epochs=100, num_layers=2, output_size=12, pass_state=True, prediction_batch_size=1, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Errors for all testing data:
mean 1 step nrmse loss: 0.4961611683642763
std: 0.09973874913810721
mean 10 step nrmse loss: 0.5335488882856138
std: 0.08772663642541334
mean 12 step nrmse loss: 0.5427283941994705
std: 0.08662141233585635


Trying 10 random samples:
mean 1 step nrmse loss: 0.5201504567701948
std: 0.10647255567387912
mean 10 step nrmse loss: 0.5610542167376601
std: 0.08099982885215853
mean 12 step nrmse loss: 0.5699081430140817
std: 0.07433164785480692
Namespace(batch_size=1, cnn_filters=[64, 128, 64], continue_from_epoch=-1, create_tensorboard=False, data_path='data', decoder_filters=[50, 50], decoder_padding='same', dropout=0, encoder_filters=[50, 50], evaluation_steps=[1, 10, 12], experiment_name='exp_1', fraction_of_data=1, fraction_of_val=1, gpu_id='None', gpus=0, grid_size=100, hidden_size=100, hidden_sizes=[256, 256], kernel_size=3, learning_rate=0.0001, learning_rate_decay=0, missing_data=0.0, mlp_hidden_sizes=[50, 1], model_file='results/convlstm_seq2seq_dropout01/saved_models/train_model_16', model_name='convlstm_seq2seq', num_epochs=100, num_layers=2, output_size=12, pass_state=True, prediction_batch_size=1, seed=7112018, segment_size=12, shuffle_order=False, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)

Errors for all testing data:
mean 1 step nrmse loss: 0.23801970457540333
std: 0.028453317940024245
mean 10 step nrmse loss: 0.33069652422444806
std: 0.04595380978937595
mean 12 step nrmse loss: 0.35223378280558887
std: 0.05286672657859623


Trying 10 random samples:
mean 1 step nrmse loss: 0.2354794237590423
std: 0.020233507100957705
mean 10 step nrmse loss: 0.33690972885783965
std: 0.03314840337586558
mean 12 step nrmse loss: 0.359844738748277
std: 0.04039724196242108
