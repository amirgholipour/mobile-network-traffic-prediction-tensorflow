Namespace(batch_size=2500, cnn_filters=[32, 64, 64], continue_from_epoch=-2, create_tensorboard=False, data_path='/home/s1310654/msc_project/data', decoder_filters=[64, 64, 64], decoder_padding='same', dropout=0, encoder_filters=[64, 64, 64], evaluation_steps=[10, 12], experiment_name='cnn_convlstm_attention_hardcoded', fraction_of_data=0.25, fraction_of_val=1, gpu_id='None', gpus=1, grid_size=100, hidden_size=100, hidden_sizes=[25, 25], kernel_size=3, learning_rate=0.001, learning_rate_decay=2e-07, missing_data=0, mlp_hidden_sizes=[50, 1], model_file='none', model_name='cnn_convlstm_attention_hardcoded', num_epochs=150, num_layers=2, output_size=12, pass_state=True, prediction_batch_size=10000, seed=7112018, segment_size=12, shuffle_order=True, train_mean=67.61768898039853, train_std=132.47248595705986, use_gpu=False, use_mini_data=False, weight_decay=1e-05, window_size=11)
